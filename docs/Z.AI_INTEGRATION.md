# üî∑ –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø Z.AI (GLM) - –û–§–ò–¶–ò–ê–õ–¨–ù–ê–Ø –ë–ò–ë–õ–ò–û–¢–ï–ö–ê

> –ü–æ–ª–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ zhipuai –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GLM-4 –∏ GLM-4.6V

---

## üì¶ –£–°–¢–ê–ù–û–í–ö–ê

### –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Z.ai

```bash
pip install zhipuai>=2.1.5.20250131
```

**–í–ê–ñ–ù–û:** 
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π **–¢–û–õ–¨–ö–û** –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É `zhipuai`
- ‚ùå –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π `openai` –¥–ª—è GLM
- ‚ùå –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä—è–º—ã–µ HTTP-–∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ `httpx` –∫ GLM API
- ‚ùå –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π `anthropic` –∏–ª–∏ –¥—Ä—É–≥–∏–µ –æ–±—ë—Ä—Ç–∫–∏

---

## üîë –ü–û–õ–£–ß–ï–ù–ò–ï API –ö–õ–Æ–ß–ê

1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Å—è –Ω–∞ https://z.ai
2. –ü–µ—Ä–µ–π–¥–∏ –≤ https://z.ai/manage-apikey/apikey-list
3. –°–æ–∑–¥–∞–π –Ω–æ–≤—ã–π API –∫–ª—é—á
4. –î–æ–±–∞–≤—å –≤ `.env`:
   ```env
   GLM_API_KEY=your_api_key_here
   ```

---

## ü§ñ –î–û–°–¢–£–ü–ù–´–ï –ú–û–î–ï–õ–ò

| –ú–æ–¥–µ–ª—å | –¢–∏–ø | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ |
|--------|-----|-----------|-------------|
| `glm-4-6v` | Vision | –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π | –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ–≤–µ–π—à–∞—è –≤–µ—Ä—Å–∏—è |
| `glm-4v-flash` | Vision | –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π | –ë—ã—Å—Ç—Ä–∞—è, —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è |
| `glm-4-plus` | Text | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ | –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ |
| `glm-4-air` | Text | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ | –ë–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞/—Å–∫–æ—Ä–æ—Å—Ç–∏ |
| `glm-4-flash` | Text | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ | –ë—ã—Å—Ç—Ä–∞—è, —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è |

---

## üìñ –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø

### 1. –ë–∞–∑–æ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

```python
from zhipuai import ZhipuAI

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞
client = ZhipuAI(api_key="your_api_key_here")
```

---

### 2. –ü—Ä–æ—Å—Ç–∞—è —Ç–µ–∫—Å—Ç–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è)

```python
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="–≤–∞—à_–∫–ª—é—á")

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
response = client.chat.completions.create(
    model="glm-4-plus",
    messages=[
        {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É"},
        {"role": "user", "content": "–ü—Ä–∏–¥—É–º–∞–π —Å–ª–æ–≥–∞–Ω –¥–ª—è —Ç–æ–≤–∞—Ä–∞"}
    ],
    temperature=0.7,
    max_tokens=500
)

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
result = response.choices[0].message.content
print(result)

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–∞—Ö
print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens}")
```

---

### 3. –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è (–¥–ª—è aiogram)

**–í–ê–ñ–ù–û:** –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ zhipuai - **—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è**, –Ω–æ –µ—ë –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —á–µ—Ä–µ–∑ `asyncio.loop.run_in_executor()`:

```python
import asyncio
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="–≤–∞—à_–∫–ª—é—á")

async def generate_async(prompt: str) -> str:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞."""
    loop = asyncio.get_event_loop()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –≤ executor
    response = await loop.run_in_executor(
        None,
        lambda: client.chat.completions.create(
            model="glm-4-plus",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
    )
    
    return response.choices[0].message.content

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
async def main():
    result = await generate_async("–ü—Ä–∏–≤–µ—Ç!")
    print(result)

asyncio.run(main())
```

---

### 4. –ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (Vision)

```python
import base64
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="–≤–∞—à_–∫–ª—é—á")

# –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
with open("photo.jpg", "rb") as f:
    image_data = f.read()

# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
image_base64 = base64.b64encode(image_data).decode("utf-8")

# –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
response = client.chat.completions.create(
    model="glm-4-6v",  # Vision –º–æ–¥–µ–ª—å
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "–û–ø–∏—à–∏ —ç—Ç–æ—Ç —Ç–æ–≤–∞—Ä –¥–µ—Ç–∞–ª—å–Ω–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—Ä—Ç–æ—á–∫–∏ –Ω–∞ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–µ"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64}"
                    }
                }
            ]
        }
    ],
    temperature=0.3
)

description = response.choices[0].message.content
print(description)
```

---

### 5. –ê–Ω–∞–ª–∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

GLM-4.6V –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ (–¥–æ 5):

```python
import base64
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="–≤–∞—à_–∫–ª—é—á")

# –ß–∏—Ç–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
image_files = ["photo1.jpg", "photo2.jpg", "photo3.jpg"]
images_base64 = []

for img_file in image_files:
    with open(img_file, "rb") as f:
        img_data = f.read()
        img_b64 = base64.b64encode(img_data).decode("utf-8")
        images_base64.append(img_b64)

# –§–æ—Ä–º–∏—Ä—É–µ–º content —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
content = [
    {
        "type": "text",
        "text": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤—Å–µ —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–∞ –∏ –¥–∞–π –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ"
    }
]

for img_b64 in images_base64:
    content.append({
        "type": "image_url",
        "image_url": {
            "url": f"data:image/jpeg;base64,{img_b64}"
        }
    })

# –ê–Ω–∞–ª–∏–∑
response = client.chat.completions.create(
    model="glm-4-6v",
    messages=[{"role": "user", "content": content}],
    temperature=0.3,
    max_tokens=2000
)

description = response.choices[0].message.content
print(description)
```

---

### 6. –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π Vision (–¥–ª—è Telegram-–±–æ—Ç–∞)

```python
import asyncio
import base64
from typing import List
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="–≤–∞—à_–∫–ª—é—á")

async def analyze_images_async(
    images_bytes: List[bytes], 
    prompt: str
) -> str:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    
    Args:
        images_bytes: –°–ø–∏—Å–æ–∫ –±–∞–π—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    
    Returns:
        –û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
    """
    # –§–æ—Ä–º–∏—Ä—É–µ–º content
    content = [{"type": "text", "text": prompt}]
    
    for img_bytes in images_bytes[:5]:  # –ú–∞–∫—Å–∏–º—É–º 5 —Ñ–æ—Ç–æ
        img_b64 = base64.b64encode(img_bytes).decode("utf-8")
        content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{img_b64}"
            }
        })
    
    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ executor
    loop = asyncio.get_event_loop()
    response = await loop.run_in_executor(
        None,
        lambda: client.chat.completions.create(
            model="glm-4-6v",
            messages=[{"role": "user", "content": content}],
            temperature=0.3,
            max_tokens=2000
        )
    )
    
    return response.choices[0].message.content

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ aiogram —Ö–µ–Ω–¥–ª–µ—Ä–µ
async def handler(message: Message):
    # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
    photo_bytes = await message.bot.download(message.photo[-1].file_id)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
    description = await analyze_images_async(
        [photo_bytes.read()],
        "–û–ø–∏—à–∏ —Ç–æ–≤–∞—Ä –Ω–∞ —Ñ–æ—Ç–æ"
    )
    
    await message.answer(description)
```

---

### 7. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

```python
from zhipuai import ZhipuAI
import logging

client = ZhipuAI(api_key="–≤–∞—à_–∫–ª—é—á")

async def safe_generate(prompt: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
    try:
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: client.chat.completions.create(
                model="glm-4-plus",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7
            )
        )
        return response.choices[0].message.content
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ GLM API: {e}")
        return None
```

---

## üèóÔ∏è –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –í –ü–†–û–ï–ö–¢

### GLMProvider –∫–ª–∞—Å—Å (–ø–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)

```python
# core/ai_providers/glm.py

import asyncio
import base64
import structlog
from typing import Optional, List
from zhipuai import ZhipuAI

from core.ai_providers.base import (
    BaseVisionProvider, 
    BaseTextProvider, 
    ProviderResponse
)

logger = structlog.get_logger()


class GLMProvider(BaseVisionProvider, BaseTextProvider):
    """
    –ü—Ä–æ–≤–∞–π–¥–µ—Ä Z.AI GLM.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É zhipuai>=2.1.5.20250131
    –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: https://open.bigmodel.cn/dev/api
    """
    
    name = "glm"
    
    # –ú–æ–¥–µ–ª–∏
    VISION_MODEL = "glm-4-6v"      # GLM-4.6V (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
    VISION_FAST = "glm-4v-flash"   # –ë—ã—Å—Ç—Ä—ã–π Vision
    TEXT_MODEL = "glm-4-plus"      # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π Text
    TEXT_FAST = "glm-4-flash"      # –ë—ã—Å—Ç—Ä—ã–π Text
    
    def __init__(
        self, 
        api_key: str,
        use_fast_models: bool = False
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.
        
        Args:
            api_key: API –∫–ª—é—á Z.AI
            use_fast_models: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å flash –º–æ–¥–µ–ª–∏ (–±—ã—Å—Ç—Ä–µ–µ)
        """
        self.api_key = api_key
        self.use_fast_models = use_fast_models
        self._client = ZhipuAI(api_key=api_key)
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π
        self.vision_model = self.VISION_FAST if use_fast_models else self.VISION_MODEL
        self.text_model = self.TEXT_FAST if use_fast_models else self.TEXT_MODEL
        
        logger.info(
            "glm_provider_initialized",
            vision_model=self.vision_model,
            text_model=self.text_model
        )
    
    async def analyze_image(
        self, 
        image_bytes: bytes,
        prompt: Optional[str] = None
    ) -> ProviderResponse:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        return await self.analyze_multiple_images([image_bytes], prompt)
    
    async def analyze_multiple_images(
        self,
        images: List[bytes],
        prompt: Optional[str] = None
    ) -> ProviderResponse:
        """–ê–Ω–∞–ª–∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–¥–æ 5)."""
        if not prompt:
            prompt = "–û–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —Ñ–æ—Ç–æ."
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º content —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        content = [{"type": "text", "text": prompt}]
        
        for img_bytes in images[:5]:
            base64_image = base64.b64encode(img_bytes).decode("utf-8")
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}"
                }
            })
        
        try:
            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ executor
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self._client.chat.completions.create(
                    model=self.vision_model,
                    messages=[{"role": "user", "content": content}],
                    temperature=0.3,
                    max_tokens=2000
                )
            )
            
            result_text = response.choices[0].message.content
            tokens_used = getattr(response.usage, 'total_tokens', None)
            
            logger.info(
                "glm_vision_success",
                model=self.vision_model,
                images_count=len(images),
                tokens=tokens_used
            )
            
            return ProviderResponse(
                success=True,
                content=result_text,
                provider_name=self.name,
                tokens_used=tokens_used
            )
            
        except Exception as e:
            error_msg = str(e)
            logger.error("glm_vision_error", error=error_msg)
            return ProviderResponse(
                success=False,
                content="",
                provider_name=self.name,
                error_message=error_msg
            )
    
    async def generate(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        max_tokens: int = 4000,
        temperature: float = 0.7
    ) -> ProviderResponse:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞."""
        messages = []
        
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        messages.append({
            "role": "user",
            "content": prompt
        })
        
        try:
            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ executor
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self._client.chat.completions.create(
                    model=self.text_model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
            )
            
            result_text = response.choices[0].message.content
            tokens_used = getattr(response.usage, 'total_tokens', None)
            
            logger.info(
                "glm_text_success",
                model=self.text_model,
                tokens=tokens_used
            )
            
            return ProviderResponse(
                success=True,
                content=result_text,
                provider_name=self.name,
                tokens_used=tokens_used
            )
            
        except Exception as e:
            error_msg = str(e)
            logger.error("glm_text_error", error=error_msg)
            return ProviderResponse(
                success=False,
                content="",
                provider_name=self.name,
                error_message=error_msg
            )
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å –∫–ª–∏–µ–Ω—Ç (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è zhipuai)."""
        pass
```

---

## ‚úÖ –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê –û–§–ò–¶–ò–ê–õ–¨–ù–û–ô –ë–ò–ë–õ–ò–û–¢–ï–ö–ò

1. **–ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è** - –Ω–µ –Ω—É–∂–Ω–æ —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è —Å HTTP-–∑–∞–ø—Ä–æ—Å–∞–º–∏
2. **–ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –º–æ–¥–µ–ª–µ–π** - –≤—Å–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ GLM –º–æ–¥–µ–ª–∏
3. **–í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫** - —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
4. **–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞** - –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ—Ç Z.ai
5. **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å aiogram** - —á–µ—Ä–µ–∑ `run_in_executor()`
6. **–ú–µ–Ω—å—à–µ –∫–æ–¥–∞** - —á–∏—â–µ –∏ –ø–æ–Ω—è—Ç–Ω–µ–µ

---

## üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï

```python
# test_glm.py
import asyncio
from core.ai_providers.glm import GLMProvider

async def test_glm():
    provider = GLMProvider(api_key="your_key")
    
    # –¢–µ—Å—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    response = await provider.generate("–°–∫–∞–∂–∏ –ø—Ä–∏–≤–µ—Ç")
    print(f"Text: {response.content}")
    
    # –¢–µ—Å—Ç Vision (—Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º)
    with open("test.jpg", "rb") as f:
        img_bytes = f.read()
    
    response = await provider.analyze_image(img_bytes)
    print(f"Vision: {response.content}")

asyncio.run(test_glm())
```

---

## üìö –ü–û–õ–ï–ó–ù–´–ï –°–°–´–õ–ö–ò

- **–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** https://open.bigmodel.cn/dev/api
- **Python SDK:** https://github.com/zhipuai/zhipuai-sdk-python-v4
- **–ü–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á:** https://z.ai/manage-apikey/apikey-list
- **–ú–æ–¥–µ–ª–∏ –∏ —Ü–µ–Ω—ã:** https://open.bigmodel.cn/pricing

---

*–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞: 2 —Ñ–µ–≤—Ä–∞–ª—è 2026*
